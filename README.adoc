= SWS image:https://travis-ci.org/swift-sunshine/swscore.svg["Build Status", link="https://travis-ci.org/swift-sunshine/swscore"]
:toc: macro
:toc-title:

toc::[]

== Introduction

An SWS application implemented in the Go Programming Language.

=== Docker Image

SWS is published as a docker image on https://hub.docker.com/r/jmazzitelli/sws[Docker hub at jmazzitelli/sws]

=== License and Copyright

See the link:./LICENSE[LICENSE file].

== Building

[NOTE]
These build instructions assume you have the following installed on your system: (1) link:http://golang.org/doc/install[Go Programming Language] which must be at least version 1.8.3, (2) link:http://git-scm.com/book/en/v2/Getting-Started-Installing-Git[git], (3) link:https://docs.docker.com/installation/[Docker], and (4) make. To run SWS on OpenShift after you build it, it is assumed you have a running OpenShift environment available to you. If you do not, you can find a set of link:#setting-up-openshift[instructions on how to set up OpenShift below]. To run SWS on Kubernetes after you built it, it is assumed you have a running Kubernetes environment available to you.

To build SWS:

* Clone this repository inside a GOPATH. These instructions will use the example GOPATH of "/source/go/swift-sunshine/swscore" but you can use whatever you want. Just change the first line of the below instructions to use your GOPATH.

[source,shell]
----
export GOPATH=/source/go/swift-sunshine/swscore
mkdir -p $GOPATH
cd $GOPATH
mkdir -p src/github.com/swift-sunshine
cd src/github.com/swift-sunshine
git clone git@github.com:swift-sunshine/swscore
export PATH=${PATH}:${GOPATH}/bin
----

* Install Glide - the Go dependency management tool that SWS uses to build itself

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make dep-install
----

* Tell the dependency manager tool to update the SWS dependencies
[NOTE]
You should only run this command if you add, remove, or modify a dependency. If you are simply git cloning and building from source, you should skip this step.

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make dep-update
----

* Build SWS

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make build
----

* At this point you can run the SWS tests

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make test
----

== Running

=== Running on OpenShift

==== Setting up OpenShift

The following section assumes that the user has link:https://github.com/openshift/origin[OpenShift Origin] installed.

The link:https://docs.openshift.org/latest/welcome/index.html[OpenShift Origin Documentation] will outline all the steps required.

You can alternatively build OpenShift Origin from source and run that. See link:hack/README.adoc[] for a quick way to do this using the *-openshift.sh scripts provided by this project.

==== Building the Docker Image

Create the SWS docker image through the "docker" make target:

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make docker
----

==== Deploying SWS to OpenShift

[NOTE]
Before deploying and running SWS, you must install and deploy link:https://istio.io[Istio] first. There are a few places that you can reference in order to learn how to do this such as link:https://github.com/redhat-developer-demos/istio-tutorial[here], link:https://blog.openshift.com/evaluate-istio-openshift/[here], and link:https://istio.io/docs/setup/kubernetes/quick-start.html[here]. There is also a link:hack/istio/openshift[OpenShift script] provided to you as a convienence to help you install Istio if you are using OpenShift.

[NOTE]
The following commands assume that the `oc` command is available in the user's path and that the user is logged in.

The deploy and undeploy commands are automated in the Makefile. The following will undeploy an old installation of SWS, if available, and deploy a new one:
----
make openshift-deploy
----

==== Undeploying SWS from OpenShift

If you want to remove SWS from your OpenShift environment, you can do so by running the following command:

[source,shell]
----
make openshift-undeploy
----

==== Reloading SWS image in OpenShift

If you already have SWS installed but you want to recreate the pod with a new docker image, you can run the following command:

[source,shell]
----
make openshift-reload-image
----

=== Running on Kubernetes

[NOTE]
These instructions may not fully work. Contributions are welcome.

==== Setting up Kubernetes

The following section assumes that the user has link:https://github.com/kubernetes/kubernetes[Kubernetes] installed.

==== Building the Docker Image

Create the SWS docker image through the "docker" make target:

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make docker
----

Note that if you are using minikube, you can build the docker image and push it directly into the minikube docker daemon using the alternative make target `minikube-docker`:

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make minikube-docker
----

==== Deploying SWS to Kubernetes

[NOTE]
Before deploying and running SWS, you must install and deploy link:https://istio.io[Istio] first. There are a few places that you can reference in order to learn how to do this such as link:https://github.com/redhat-developer-demos/istio-tutorial[here], link:https://blog.openshift.com/evaluate-istio-openshift/[here], and link:https://istio.io/docs/setup/kubernetes/quick-start.html[here]. There is also a link:hack/istio/kubernetes[Kubernetes script] provided to you as a convienence to help you install Istio if you are using Kubernetes.

[NOTE]
The following commands assume that the `kubectl` command is available in the user's path and that the user is logged in.

[NOTE]
In order to deploy on Kubernetes and to be able to access the deployed service, you must ensure you have Ingress support. If you are using minikube, you need to run `minikube addons enable ingress` and add `sws` as a hostname in your `/etc/hosts` via something like this command: `echo "$(minikube ip) sws" | sudo tee -a /etc/hosts`

The deploy and undeploy commands are automated in the Makefile. The following will undeploy an old installation of SWS, if available, and deploy a new one:
----
make k8s-deploy
----

==== Undeploying SWS from Kubernetes

If you want to remove SWS from your Kubernetes environment, you can do so by running the following command:

[source,shell]
----
make k8s-undeploy
----

==== Reloading SWS image in Kubernetes

If you already have SWS installed but you want to recreate the pod with a new docker image, you can run the following command:

[source,shell]
----
make k8s-reload-image
----

=== Running Standalone

Sometimes you may want to run SWS outside of any container environment, perhaps for debugging purposes. To do this, run:

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make install
make run
----

The "install" target installs the SWS executable in your GOPATH /bin directory so you can run it outside of the Makefile:

[source,shell]
----
cd ${GOPATH}/src/github.com/swift-sunshine/swscore
make install
${GOPATH}/bin/sws -config <your-config-file>
----

== Environment Variables

Many configuration settings can optionally be set via environment variables. If one of the environment variables below are set, they serve as the default value for its associated YAML configuration setting. The following are currently supported:

[cols="1a,1a"]
|===
|Environment Variable Name|Description and YAML Setting

|`IDENTITY_CERT_FILE`
|Certificate file used to identify the file server. If set, you must go over https to retrieve content from the file server.
[source,yaml]
----
identity:
  cert_file: VALUE
----

|`IDENTITY_PRIVATE_KEY_FILE`
|Private key file used to identify the server. If set, you must go over https to retrieve content from the file server.
[source,yaml]
----
identity:
  private_key_file: VALUE
----

|`SERVER_ADDRESS`
|Where the http server is bound to.
[source,yaml]
----
server:
  address: VALUE
----

|`SERVER_PORT`
|Where the http server is listening.
[source,yaml]
----
server:
  port: VALUE
----

|`SERVER_CREDENTIALS_USERNAME`
|If this (and password) is set, these credentials are required in order to get content from the server.
[source,yaml]
----
server:
  credentials:
    username: VALUE
----

|`SERVER_CREDENTIALS_PASSWORD`
|If this (and username) is set, these credentials are required in order to get content from the server.
[source,yaml]
----
server:
  credentials:
    password: VALUE
----

|`SERVER_CORS_ALLOW_ALL`
|When true, allows the web console to send requests to other domains other than where the console came from. Typically used for development environments only.
[source,yaml]
----
server:
  cors_allow_all: (true\|false)
----

|`SERVER_STATIC_CONTENT_ROOT_DIRECTORY`
|The file server will serve all static content found under this root directory.
[source,yaml]
----
server:
  static_content_root_directory: VALUE
----

|`PROMETHEUS_SERVICE_URL`
|The URL used to access and query the Prometheus Server.
[source,yaml]
----
prometheus_service_url: VALUE
----

|`GRAFANA_DISPLAY_LINK`
|When true, a link to Grafana will be displayed for more metrics.
[source,yaml]
----
grafana:
  display_link: (true\|false)
----

|`GRAFANA_URL`
|The URL to the Grafana server. When not set, the URL may be automatically detected from OpenShift or Kubernetes API.
[source,yaml]
----
grafana:
  url: VALUE
----

|`GRAFANA_SERVICE_NAMESPACE`
|The Kubernetes namespace that holds the Grafana service. This configuration is ignored if `GRAFANA_URL` is set. Default is `istio-system`.
[source,yaml]
----
grafana:
  service_namespace: VALUE
----

|`GRAFANA_SERVICE`
|The OpenShift route name or the Kubernetes service name for Grafana. This configuration is ignored if `GRAFANA_URL` is set. Default is `grafana`.
[source,yaml]
----
grafana:
  service: VALUE
----

|`GRAFANA_DASHBOARD`
|The name of the Grafana dashboard used as a landing page. Default is `istio-dashboard`.
[source,yaml]
----
grafana:
  dashboard: VALUE
----

|`GRAFANA_VAR_SERVICE_SOURCE`
|The name of the Grafana variable that controls service sources, as defined in the configured `GRAFANA_DASHBOARD`. Default is `var-source`.
[source,yaml]
----
grafana:
  var_service_source: VALUE
----

|`GRAFANA_VAR_SERVICE_DEST`
|The name of the Grafana variable that controls service destinations, as defined in the configured `GRAFANA_DASHBOARD`. Default is `var-http_destination`.
[source,yaml]
----
grafana:
  var_service_dest: VALUE
----

|===

== Additional Notes

=== Running the UI Outside the Core

When developing the http://github.com/swift-sunshine/swsui[SWS UI] you will find it useful to run it outside of the core to make it easier to update the UI code and see the changes without having to recompile. The prefered approach for this is to use a proxy on the UI to mount the core. The process is described https://github.com/swift-sunshine/swsui#developing[here].

=== Running A Locally Built UI Inside the Core

If you are developing the UI on your local machine but you want to see it deployed and running inside of the core server, you can do so by setting the environment variable CONSOLE_VERSION to the value "local" when building the docker image via the `docker` target. By default, your UI's build/ directory is assumed to be in a directory called `swsui` that is a peer directory of the GOPATH root directory for the core server. If it is not, you can set the environment variable CONSOLE_LOCAL_DIR to the value of the path of the root directory for the UI such that `$CONSOLE_LOCAL_DIR/build` contains the generated build files for the UI.

For example, if your GOPATH directory for the swscore project is `/source/swift-sunshine/swscore` and you have git cloned the swsui repository in `/source/swift-sunshine/swsui` then you do not need to set CONSOLE_LOCAL_DIR. You can embed your locally built console into the core docker image via:

[source,shell]
----
CONSOLE_VERSION=local make docker
----

If you git cloned the swsui repository in directory `/my/git/repo` and have built the UI there (such that the build files are located at `/my/git/repo/build`) then you can embed that locally built console into the core docker image via:

[source,shell]
----
CONSOLE_VERSION=local CONSOLE_LOCAL_DIR=/my/git/repo make docker
----
